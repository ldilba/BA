\section{Einleitung}
\subsection{Motivation und Hintergrund}
Jeden Tag werden weltweit riesige Mengen an Daten - im Jahr 2020 beispielsweise 64,2 Zettabyte - produziert.\footcite{statista2022daten} Dies entspricht 64,2 Billionen Gigabyte. Mithilfe von Datenmanagement und Datenanalyse wird versucht, die Daten so weit aufzubereiten, dass sie durch Menschen und Algorithmen ausgewertet werden können. Je nach Datenmenge und Abweichung der Daten untereinander kann dies ein aufwändiger und damit teurer Prozess sein. Bei größerer Komplexität oder Menge der Daten wird es für Menschen schwerer, Zusammenhänge, Abweichungen und Auffälligkeiten zu erkennen. Dies liegt u. a. daran, dass Muster von neu erfassten Daten nur durch Erinnerungen aus dem Kurzzeitgedächtnis abgeleitet werden können.\footcite{snyder2000music} Um dieses Problem zu lösen, wurden Algorithmen entwickelt, die mit großen Datenmengen trainiert werden, um allgemeine Aussagen über die eingegebenen Daten zu treffen. Je nach Datenquelle und Art der Aussage, die über diese Daten getroffen werden soll, bedarf es an werden unterschiedlichen Algorithmen aus dem Bereich der \ac{ki}. Durch den Anschluss  einer Datenquelle mit einer KI entsteht eine feste Verdrahtung zwischen dem Datenerhebungsalgorithmus und dem KI-gestützten Datenverarbeitungsalgorithmus. Sollte sich entweder die Datenerhebung oder die Auswertung verändern, muss in der Regel die Anbindung der Datenquelle an die KI überarbeitet werden. Dies erfordert spezifisches Know-how im Bereich der eingesetzten KI, der Datenerhebung und der bereits programmierten Schnittstellen.

\subsection{Problemstellung}
Jede KI benötigt Daten in einem bestimmten Format. KI-basierte Textanalysealgorithmen, beispielsweise der von Google entwickelte BERT-Algorithmus, benötigen reinen ASCII-Text als Input. Ein Entwickler, der eine KI mit gesammelten Daten benutzen möchte, muss diese Daten in das von der KI benötigte Format übertragen. Bei einem Austausch der KI oder des Datenerhebungsalgorithmus hat der Entwickler die Daten auf Kompatibilität und das Ergebnis auf Korrektheit zu prüfen.

Das Thema der Bachelorarbeit ist die Konzeption und Entwicklung einer Schnittstelle, die den Anschluss von Daten an KI-gestützte Datenverarbeitungsalgorithmen vereinfacht. Wie kann ein Entwickler nach Einrichtung der KI die Daten austauschen, ohne die Schnittstelle neu programmieren zu müssen? Wie kann ein Entwickler eine bereits eingesetzte KI mit einer anderen austauschen, ohne die Daten verändern zu müssen?

\subsection{Zielsetzung}
Die im Rahmen der Bachelorarbeit entwickelte Schnittstelle bietet diverse Vorteile. Die Schnittstelle ermöglicht, Daten zur Laufzeit der Anwendung einzugeben und diese Daten an einen KI-gestützten Datenverarbeitungsalgorithmus anzuschließen. Ferner ermöglicht die Schnittstelle den dynamischen Austausch der KI. Der Anwender konfiguriert den Anschluss der Daten über eine Transformationsanleitung, um die Anfrage für die KI vorzubereiten. Das aus der KI resultierende Ergebnis wird dem Nutzer angezeigt. Die Konzeption der Schnittstelle wird mit einem Textanalysealgorithmus implementiert, der eine semantische Suche innerhalb eines Textes durchführt. Das Backend ist als REST-API entwickelt. Dadurch können Entwickler die Schnittstelle mit unterschiedlichen oder veränderten Daten und KIs nutzen. Durch die Schnittstelle verringert sich der Arbeitsaufwand, der durch die Anbindung und Nutzung neuer KIs entsteht. Entwickler werden entlastet sowie Personalkosten verringert. 
Schließlich können alternativen Aufbereitungen der Daten und neue KIs mit geringem Mehraufwand getestet werden.

\subsection{CONET Solutions GmbH}
\begin{table}[H]
\begin{tabular}{ l l }
Firma: & CONET Solutions GmbH \\
Muttergesellschaft: & CONET Technologies Holding GmbH \\
Hauptsitz: & Theodor-Heuss-Allee 19, 53773 Hennef (Sieg) \\
Geschäftsführer: & Dirk Lieder \\
Gründungsjahr: & 1987 
\end{tabular}
\end{table}

Das \ac{conet} ist ein IT-Beratungsunternehmen, welches in vielen Bereichen Dienstleistungen anbietet. Das Spektrum der Dienstleistungen umfasst u. a. SAP Consulting, Cyber Security, Cloud Computing, Data Intelligence, Digital Communications \& E-Commerce, Critical Communications, Agile Software Development und Management Consulting. CONET ist spezialisiert auf die Entwicklung von Individualsoftware. CONET ist sowohl im privaten als auch im öffentlichen Sektor vertreten. Zu den Kunden gehören u. a. Bundeswehr, Volkswagen AG, Telekom, Deutsche Bahn. \footcite [Auszug aus der Kundenliste]{Kunden} CONET ist an 20 Standorten in Europa vertreten.

Thema der Bachelorarbeit, Anforderungserhebung sowie Evaluation wurde gemeinsam mit CONET erarbeitet. 

\subsection{Vorgehen}
Die Bachelorarbeit wird eingeleitet mit der Darstellung von Motivation, Problemstellung und Zielsetzung sowie Vorstellung der die Arbeit betreuenden CONET Solutions GmbH. Kapitel 2 erläutert die Grundlagen der Bachelorarbeit.  Dargelegt werden Konzepte einer Schnittstelle sowie Methoden zur Kommunikation. APIs, der REST-Architekturstil sowie die Middleware RabbitMQ werden beschrieben. Gleiches gilt für Microservice-Architekturen, auf denen das Konzept der entwickelten Schnittstelle aufbaut. Anschließend wird in das Thema KI eingeführt. Das Kapitel endet mit einer Auflistung und Erläuterung der Einsatzzwecke der für die Bachelorarbeit genutzten Werkzeuge.

Das Kapitel 3 stellt die Methodik dar, mit der die Bachelorarbeit bearbeitet und die Schnittstelle entwickelt wurde. Das Wasserfallmodell wurde als Projektmanagementmethode für die Entwicklung der Schnittstelle beschrieben und mit Begründung ausgewählt.

In Kapitel 4 werden die Ergebnisse der Anforderungserhebung sowie ein Konzept für die Architektur der Schnittstelle beschrieben. Dargestellt werden der Programmablauf und die geplante visuelle Darstellung der Website in Form von Mockups. Abschließend erläutert das Kapitel die technische Umsetzung der einzelnen Bestandteile der Architektur und das Deployment der Software.

Das Kapitel 5 stellt die Evaluation der Schnittstelle dar, einschließlich der mit CONET erarbeiteten Ergebnisse der Code-Reviews.

In Kapitel 6, Fazit und Ausblick, werden etwaige Implikation für die Forschung dargestellt, die aus den entwickelten Komponenten für die Schnittstelle resultieren. Abschließend werden die für einen Einsatz der Schnittstelle in einer Produktivumgebung zwingend erforderlichen sowie sonstige Erweiterungen beschrieben.



